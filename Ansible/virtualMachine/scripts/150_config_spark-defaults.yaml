---
- hosts: master
  tasks:
    - name: Create the spark-defaults.conf file
      copy:
        src: /opt/hadoop/spark/conf/spark-defaults.conf.template
        dest: /opt/hadoop/spark/conf/spark-defaults.conf
        remote_src: yes
      become: true
      become_user: root


    - name: Update the spark-defaults.conf file
      blockinfile:
        path: /opt/hadoop/spark/conf/spark-defaults.conf
        block: |
          spark.master                      yarn
          spark.driver.memory               512m
          spark.yarn.am.memory              512m
          spark.executor.memory             512m
          spark.eventLog.enabled            true
          spark.eventLog.dir                hdfs://master:9000/spark-logs
          spark.history.provider            org.apache.spark.deploy.history.FsHistoryProvider
          spark.history.fs.logDirectory     hdfs://master:9000/spark-logs
          spark.history.fs.update.interval  10s
          spark.history.ui.port             18080          
          spark.executors.cores             5
          spark.executor.extraJavaOptions   -XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions -XX:+G1SummarizeConcMark -XX:InitiatingHeapOccupancyPercent=35 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:OnOutOfMemoryError='kill -9 %p'
          spark.driver.extraJavaOptions     -XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions -XX:+G1SummarizeConcMark -XX:InitiatingHeapOccupancyPercent=35 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:OnOutOfMemoryError='kill -9 %p'
      become: true
      become_user: root


    # - name: Update the spark-defaults.conf file - link spark with yarn
    #   blockinfile:
    #     path: /opt/hadoop/spark/conf/spark-defaults.conf
    #     block: |
    #       spark.master    yarn
    #   become: true
    #   become_user: root

    # - name: Update the spark-defaults.conf file - set spark memory usage
    #   blockinfile:
    #     path: /opt/hadoop/spark/conf/spark-defaults.conf
    #     block: |
    #       spark.driver.memory     256m
    #       spark.yarn.am.memory    256m
    #       spark.executor.memory   256m
    #   become: true
    #   become_user: root

    # - name: Update the spark-defaults.conf file - set monitoring
    #   blockinfile:
    #     path: /opt/hadoop/spark/conf/spark-defaults.conf
    #     block: |
    #       spark.eventLog.enabled  true
    #       spark.eventLog.dir hdfs://node-master:9000/spark-logs
    #   become: true
    #   become_user: root

    # - name: Update the spark-defaults.conf file - set logs
    #   blockinfile:
    #     path: /opt/hadoop/spark/conf/spark-defaults.conf
    #     block: |
    #       spark.history.provider            org.apache.spark.deploy.history.FsHistoryProvider
    #       spark.history.fs.logDirectory     hdfs://node-master:9000/spark-logs
    #       spark.history.fs.update.interval  10s
    #       spark.history.ui.port             18080
    #   become: true
    #   become_user: root
